{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SpealLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n",
      "[NumericColumn(key='SpealLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LUCASB~1\\AppData\\Local\\Temp\\tmpkyyrthdq\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LUCASB~1\\\\AppData\\\\Local\\\\Temp\\\\tmpkyyrthdq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LUCASB~1\\AppData\\Local\\Temp\\tmpkyyrthdq\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 3.1741543, step = 0\n",
      "INFO:tensorflow:global_step/sec: 605.51\n",
      "INFO:tensorflow:loss = 2.0569966, step = 100 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.691\n",
      "INFO:tensorflow:loss = 1.8319447, step = 200 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.574\n",
      "INFO:tensorflow:loss = 1.5240601, step = 300 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.694\n",
      "INFO:tensorflow:loss = 1.3413292, step = 400 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.568\n",
      "INFO:tensorflow:loss = 1.2394681, step = 500 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.696\n",
      "INFO:tensorflow:loss = 1.2035428, step = 600 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.699\n",
      "INFO:tensorflow:loss = 1.1355047, step = 700 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.691\n",
      "INFO:tensorflow:loss = 1.1157194, step = 800 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.694\n",
      "INFO:tensorflow:loss = 1.1071823, step = 900 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.574\n",
      "INFO:tensorflow:loss = 1.0880756, step = 1000 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.266\n",
      "INFO:tensorflow:loss = 1.0746912, step = 1100 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.693\n",
      "INFO:tensorflow:loss = 1.070308, step = 1200 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.575\n",
      "INFO:tensorflow:loss = 1.0546153, step = 1300 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.931\n",
      "INFO:tensorflow:loss = 1.0365493, step = 1400 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.771\n",
      "INFO:tensorflow:loss = 1.0270107, step = 1500 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.266\n",
      "INFO:tensorflow:loss = 1.0085235, step = 1600 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.579\n",
      "INFO:tensorflow:loss = 1.0142164, step = 1700 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.569\n",
      "INFO:tensorflow:loss = 0.9913753, step = 1800 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.924\n",
      "INFO:tensorflow:loss = 0.98400736, step = 1900 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.194\n",
      "INFO:tensorflow:loss = 0.96792126, step = 2000 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.532\n",
      "INFO:tensorflow:loss = 0.96597916, step = 2100 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.574\n",
      "INFO:tensorflow:loss = 0.96896493, step = 2200 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.662\n",
      "INFO:tensorflow:loss = 0.9405422, step = 2300 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.58\n",
      "INFO:tensorflow:loss = 0.942824, step = 2400 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 780.535\n",
      "INFO:tensorflow:loss = 0.94460905, step = 2500 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.276\n",
      "INFO:tensorflow:loss = 0.93537074, step = 2600 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.534\n",
      "INFO:tensorflow:loss = 0.928579, step = 2700 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.267\n",
      "INFO:tensorflow:loss = 0.9353758, step = 2800 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.931\n",
      "INFO:tensorflow:loss = 0.9243189, step = 2900 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.274\n",
      "INFO:tensorflow:loss = 0.9094417, step = 3000 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.919\n",
      "INFO:tensorflow:loss = 0.8988466, step = 3100 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.696\n",
      "INFO:tensorflow:loss = 0.8975686, step = 3200 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.569\n",
      "INFO:tensorflow:loss = 0.89384675, step = 3300 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.814\n",
      "INFO:tensorflow:loss = 0.8860378, step = 3400 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.576\n",
      "INFO:tensorflow:loss = 0.895278, step = 3500 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.693\n",
      "INFO:tensorflow:loss = 0.8783366, step = 3600 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.693\n",
      "INFO:tensorflow:loss = 0.8766619, step = 3700 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.696\n",
      "INFO:tensorflow:loss = 0.88367915, step = 3800 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.688\n",
      "INFO:tensorflow:loss = 0.85523, step = 3900 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.679\n",
      "INFO:tensorflow:loss = 0.8502272, step = 4000 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.294\n",
      "INFO:tensorflow:loss = 0.85817057, step = 4100 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.572\n",
      "INFO:tensorflow:loss = 0.8559477, step = 4200 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.927\n",
      "INFO:tensorflow:loss = 0.85232455, step = 4300 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.691\n",
      "INFO:tensorflow:loss = 0.8352312, step = 4400 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.926\n",
      "INFO:tensorflow:loss = 0.83017683, step = 4500 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.691\n",
      "INFO:tensorflow:loss = 0.82743114, step = 4600 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.691\n",
      "INFO:tensorflow:loss = 0.82404166, step = 4700 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.573\n",
      "INFO:tensorflow:loss = 0.8204646, step = 4800 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.925\n",
      "INFO:tensorflow:loss = 0.8137512, step = 4900 (0.121 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\LUCASB~1\\AppData\\Local\\Temp\\tmpkyyrthdq\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.8288095.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1fcb364af98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SpealLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "#Load Dataset:\n",
    "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0) #header=0 betyder bare at row 0 er header\n",
    "test = pd.read_csv(test_path,names=CSV_COLUMN_NAMES, header=0)\n",
    "\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "print(train.head())\n",
    "\n",
    "#Input Funciton:\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    #Konveterer data til dataset:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    #Shuffle hvis det er træningsdata:\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "#Feature Columns:\n",
    "my_feature_columns =[]\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)\n",
    "\n",
    "#Building The Model:\n",
    "#tf.get_logger().setLevel('INFO') #Giver output mens den træner DNN.\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,hidden_units=[30,10], n_classes=3)\n",
    "\n",
    "classifier.train(input_fn=lambda: input_fn(train, train_y, training=True),steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2024-03-22T17:04:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LUCASB~1\\AppData\\Local\\Temp\\tmpkyyrthdq\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14713s\n",
      "INFO:tensorflow:Finished evaluation at 2024-03-22-17:04:48\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.43333334, average_loss = 0.89488536, global_step = 5000, loss = 0.89488536\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\LUCASB~1\\AppData\\Local\\Temp\\tmpkyyrthdq\\model.ckpt-5000\n",
      "\n",
      "Test set Accuracy: 0.433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Estimator:\n",
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set Accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi prøver nu at predicte en blomst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:346 call  *\n        net = self._input_layer(features, training=is_training)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\keras\\feature_column\\dense_features.py:169 call  **\n        self._state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2697 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2669 transform_feature\n        input_tensor = transformation_cache.get(self.key, state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2444 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature PetalLength is not in features dictionary.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-37dd2897859b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpred_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mclass_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprobability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'probabilities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[0;32m    612\u001b[0m             input_fn, ModeKeys.PREDICT)\n\u001b[0;32m    613\u001b[0m         estimator_spec = self._call_model_fn(features, None, ModeKeys.PREDICT,\n\u001b[1;32m--> 614\u001b[1;33m                                              self.config)\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;31m# Call to warm_start has to be after model_fn is called.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    755\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m           batch_norm=batch_norm)\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     super(DNNClassifierV2, self).__init__(\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_model_fn_v2\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    562\u001b[0m       \u001b[0mbatch_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m       mode=mode)\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m   \u001b[1;31m# In TRAIN mode, create optimizer and assign global_step variable to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn_builder_v2\u001b[1;34m(units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, features, mode)\u001b[0m\n\u001b[0;32m    498\u001b[0m       \u001b[0mbatch_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m       name='dnn')\n\u001b[1;32m--> 500\u001b[1;33m   \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m   \u001b[0mtrainable_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m   \u001b[0mupdate_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    763\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m    764\u001b[0m                   self._compute_dtype_object):\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:346 call  *\n        net = self._input_layer(features, training=is_training)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\keras\\feature_column\\dense_features.py:169 call  **\n        self._state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2697 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2669 transform_feature\n        input_tensor = transformation_cache.get(self.key, state_manager)\n    c:\\Users\\Lucas Bonde\\anaconda3\\envs\\MLFUN\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2444 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature PetalLength is not in features dictionary.\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLegth', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + ': ')\n",
    "        if not val.isdigit(): valid = False\n",
    "\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    print(pred_dict)\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100 * probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLFUN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
